{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DeepMind Lab Maze experiments",
   "id": "3335462cd89d3061"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Before this notebook can be run and the models evaluated the data must be prepared. Ensure you have completed all the steps outlined in dm_setup_instructions.txt.",
   "id": "dccfa6a122528e1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "import pathlib\n",
    "import pydpf\n",
    "import torch\n",
    "import dm_model\n",
    "import dm_neural_networks\n",
    "import dm_training\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "1adc01df674ae529",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "observation_encoding_size = 128\n",
    "state_encoding_size = 64\n",
    "scaling = 1000.\n",
    "DPF_types = ['DPF', 'Soft', 'Stop-Gradient', 'Marginal Stop-Gradient', 'Optimal Transport', 'Kernel']\n",
    "deterministic = True\n",
    "if deterministic:\n",
    "    results_file = 'results/deep_mind_maze_results.csv'\n",
    "else:\n",
    "    results_file = 'results/nondeterministic_deep_mind_maze_results.csv'"
   ],
   "id": "a1167460b876a853",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def flatten_gens(list_of_gens):\n",
    "    return [item for gen in list_of_gens for item in gen]\n",
    "    \n",
    "def is_in_it(item, it):\n",
    "    return any(id(item) == id(item_) for item_ in it)\n",
    "    \n",
    "\n",
    "def get_SSM():\n",
    "    \"\"\"\n",
    "    Build the model from components\n",
    "    \"\"\"\n",
    "    encoder = dm_neural_networks.ObservationEncoder(observation_encoding_size, generator=cuda_gen, dropout_keep_ratio=0.3)\n",
    "    decoder = dm_neural_networks.ObservationDecoder(observation_encoding_size, generator=cuda_gen, dropout_keep_ratio=0.3)\n",
    "    state_encoder = dm_neural_networks.StateEncoder(state_encoding_size, generator=cuda_gen, dropout_keep_ratio=0.6)\n",
    "    observation_partial_flows = [dm_neural_networks.RealNVP_cond(dim = observation_encoding_size, hidden_dim=observation_encoding_size, condition_on_dim=state_encoding_size, generator = cuda_gen, zero_i=True), dm_neural_networks.RealNVP_cond(dim = observation_encoding_size, hidden_dim=observation_encoding_size, condition_on_dim=state_encoding_size, generator = cuda_gen, zero_i=True)]\n",
    "    flow_cov = torch.nn.Parameter(torch.eye(observation_encoding_size, device=device)*1, requires_grad=False)\n",
    "    observation_flow = dm_neural_networks.NormalizingFlowModel_cond(pydpf.MultivariateGaussian(torch.zeros(observation_encoding_size, device=device), cholesky_covariance= flow_cov, diagonal_cov=True, generator=cuda_gen), observation_partial_flows, device)\n",
    "    observation_model = dm_model.MazeObservation(observation_flow, encoder, decoder, state_encoder, device=device)\n",
    "    dynamic_cov = torch.diag(torch.tensor([30/(scaling), 30/(scaling), 0.1], device=device))\n",
    "    dynamic_model = dm_model.MazeDynamic(cuda_gen, dynamic_cov)\n",
    "    prior_model = dm_model.MazePrior(2*1000/scaling, 1.3*1000/scaling, cuda_gen)\n",
    "    encoder_parameters = flatten_gens([encoder.parameters(), state_encoder.parameters(), decoder.parameters()])\n",
    "    flow_parameters = flatten_gens([observation_flow.parameters(), prior_model.parameters()])\n",
    "    SSM = pydpf.FilteringModel(dynamic_model=dynamic_model, prior_model=prior_model, observation_model=observation_model)\n",
    "    #print(f'observation encoder ps {sum(p.numel() for p in encoder.parameters())}')\n",
    "    #print(f'state encoder ps {sum(p.numel() for p in state_encoder.parameters())}')\n",
    "    #print(f'decoder ps {sum(p.numel() for p in decoder.parameters())}')\n",
    "    #print(f'observation flow ps {sum(p.numel() for p in observation_flow.parameters())}')\n",
    "    return SSM, encoder_parameters, flow_parameters, [flow_cov]\n",
    "            "
   ],
   "id": "7b67079e3a4c7815",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def transform_control(control, **data):\n",
    "    output = control/torch.tensor([[[scaling, scaling, 1.]]], device=device)\n",
    "    return output\n",
    "    "
   ],
   "id": "5356bc7254f10704",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def normalise_obs(observation, **data):\n",
    "    return (observation - torch.mean(observation))/torch.std(observation)\n",
    "    "
   ],
   "id": "a24666d4fefec5c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_DPF(SSM):\n",
    "    if DPF_type == 'DPF':\n",
    "        return pydpf.DPF(SSM=SSM, resampling_generator=cuda_gen)\n",
    "    if DPF_type == 'Soft':\n",
    "        return pydpf.SoftDPF(SSM=SSM, resampling_generator=cuda_gen)\n",
    "    if DPF_type == 'Stop-Gradient':\n",
    "        return pydpf.StopGradientDPF(SSM=SSM, resampling_generator=cuda_gen)\n",
    "    if DPF_type == 'Marginal Stop-Gradient':\n",
    "        return pydpf.MarginalStopGradientDPF(SSM=SSM, resampling_generator=cuda_gen)\n",
    "    if DPF_type == 'Optimal Transport':\n",
    "        return pydpf.OptimalTransportDPF(SSM=SSM, regularisation=1.)\n",
    "    if DPF_type == 'Kernel':\n",
    "        Gaussian_kernel = pydpf.StandardGaussian(3, cuda_gen, learn_mean=False, learn_cov=True)\n",
    "        kernel_mixture = pydpf.KernelMixture(kernel=Gaussian_kernel, generator=cuda_gen)\n",
    "        return pydpf.KernelDPF(SSM=SSM, kernel=kernel_mixture)\n",
    "    raise ValueError('DPF_type should be one of the allowed options')"
   ],
   "id": "645de5427a21adb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with pydpf.utils.set_deterministic_mode(deterministic, True):\n",
    "    for DPF_type in DPF_types:\n",
    "        total_MSE = 0\n",
    "        total_time = 0\n",
    "        #repeat five times\n",
    "        for i in range(1):\n",
    "            cuda_gen = torch.Generator(device=device).manual_seed(i*10)\n",
    "            SSM, encoder_params, flow_params, flow_cov = get_SSM()\n",
    "            dpf = get_DPF(SSM)\n",
    "            dpf.to(device)\n",
    "            if DPF_type == 'Kernel':\n",
    "                opt = torch.optim.AdamW([{'params': encoder_params, 'lr': 0.005}, {'params': flow_params, 'lr': 0.001}, {'params': dpf.resampler.mixture.parameters(), 'lr': 0.001, 'weight_decay': 0}], weight_decay=1e-3, betas=(0.7, 0.98), eps=1e-9)\n",
    "            else:\n",
    "                opt = torch.optim.AdamW([{'params': encoder_params, 'lr': 0.005}, {'params': flow_params, 'lr': 0.001}], weight_decay=1e-2, betas=(0.8, 0.99), eps=1e-9)\n",
    "            opt_scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.99)\n",
    "            data = pydpf.StateSpaceDataset(data_path= pathlib.Path('.').parent.absolute().joinpath('data/maze_data.csv'), state_prefix='state', control_prefix='control', device = device)\n",
    "            data.apply(normalise_obs,  'observation')\n",
    "            scaling_tensor = torch.tensor([[[scaling, scaling, 1.]]], device=device)\n",
    "            data.apply(lambda state, **data: (state - torch.tensor([[[1000., 650., 0.]]], device=device))/scaling_tensor, 'state')\n",
    "            data.apply(transform_control, 'control')\n",
    "            print('Data Loaded')\n",
    "            start_time = time.time()\n",
    "            test_mse, _ = dm_training.train(dpf, opt, data, 2, (100, 100, 100), (64, 64, 64), (0.45, 0.2, 0.35), (1., 1., 1.), torch.Generator().manual_seed(i*10), None, 'MSE', 99, pre_train_epochs=0, device=device, lr_scheduler=opt_scheduler, state_scaling = scaling)\n",
    "            total_MSE += test_mse\n",
    "            total_time += time.time() - start_time\n",
    "        MSE = total_MSE / 5\n",
    "        runtime = total_time/5\n",
    "        result_path = pathlib.Path('.').parent.absolute().joinpath(results_file)\n",
    "        results = pd.read_csv(result_path, index_col=0)\n",
    "        row = [str(datetime.timedelta(seconds=runtime)), math.sqrt(MSE)]\n",
    "        results.loc[DPF_type] = row\n",
    "        print(results)\n",
    "        results.to_csv(result_path)\n"
   ],
   "id": "262e79dca2f4d309",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
