{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-05T12:51:13.952065Z",
     "start_time": "2025-06-05T12:51:13.944133Z"
    }
   },
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pydpf\n",
    "import model\n",
    "import pathlib\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from math import sqrt"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:51:13.959298Z",
     "start_time": "2025-06-05T12:51:13.954076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dx = 25\n",
    "dy = 1\n",
    "n_repeats = 5\n",
    "data_path = pathlib.Path('.').parent.absolute().joinpath('data.csv')\n",
    "result_path = pathlib.Path('.').parent.absolute().joinpath('proposal_learning_results.csv')\n",
    "Ks = [None, 25, 100, 1000, 10000]\n",
    "generate_data = False\n",
    "#experiment_list = ['Bootstrap', 'Optimal', 'DPF', 'Soft', 'Stop-Gradient', 'Marginal Stop-Gradient', 'Optimal Transport', 'Kernel']\n",
    "experiment_list = ['Optimal Transport', 'Kernel']\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cuda_gen = torch.Generator(device=device).manual_seed(0)\n",
    "cpu_gen = torch.Generator().manual_seed(0)"
   ],
   "id": "8f836606d041aa09",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:51:13.989066Z",
     "start_time": "2025-06-05T12:51:13.985194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_model_componets(dx, dy, generator, optimal_prop = True):\n",
    "    dynamic_model = model.GaussianDynamic(dx, generator)\n",
    "    observation_model = model.GaussianObservation(dx, dy, generator)\n",
    "    prior_model = model.GaussianPrior(dx, generator)\n",
    "    if optimal_prop:\n",
    "        proposal_model = model.GaussianOptimalProposal(dx, dy, generator)\n",
    "    else:\n",
    "        proposal_model = model.GaussianLearnedProposal(dx, dy, generator)\n",
    "    return prior_model, dynamic_model, observation_model, proposal_model"
   ],
   "id": "f6d4c6b36aa55a8a",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:51:14.021351Z",
     "start_time": "2025-06-05T12:51:14.017632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if generate_data:\n",
    "    gen_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    gen_generator = torch.Generator(device=gen_device).manual_seed(0)\n",
    "    prior_model, dynamic_model, observation_model, _ = make_model_componets(dx, dy, gen_generator)\n",
    "    SSM = pydpf.FilteringModel(prior_model=prior_model, dynamic_model=dynamic_model, observation_model=observation_model)\n",
    "    pydpf.simulate_and_save(data_path, SSM=SSM, time_extent=1000, n_trajectories=2000, batch_size=100, device=gen_device)"
   ],
   "id": "9447b123bbd7a7e1",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:51:14.055717Z",
     "start_time": "2025-06-05T12:51:14.051291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_DPF(DPF_type, SSM, dim):\n",
    "    if DPF_type == 'DPF':\n",
    "        return pydpf.DPF(SSM=SSM, resampling_generator=cuda_gen)\n",
    "    if DPF_type == 'Soft':\n",
    "        return pydpf.SoftDPF(SSM=SSM, resampling_generator=cuda_gen)\n",
    "    if DPF_type == 'Stop-Gradient':\n",
    "        return pydpf.StopGradientDPF(SSM=SSM, resampling_generator=cuda_gen)\n",
    "    if DPF_type == 'Marginal Stop-Gradient':\n",
    "        return pydpf.MarginalStopGradientDPF(SSM=SSM, resampling_generator=cuda_gen)\n",
    "    if DPF_type == 'Optimal Transport':\n",
    "        return pydpf.OptimalTransportDPF(SSM=SSM, regularisation=0.5)\n",
    "    if DPF_type == 'Kernel':\n",
    "        kernel = pydpf.KernelMixture([('Gaussian', dim)], gradient_estimator='reparameterisation', generator=cuda_gen)\n",
    "        return pydpf.KernelDPF(SSM=SSM, kernel=kernel)\n",
    "    raise ValueError('DPF_type should be one of the allowed options')"
   ],
   "id": "7cd900020f0d005a",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:51:14.091497Z",
     "start_time": "2025-06-05T12:51:14.085915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def training_loop(dpf, epochs, train_loader, validation_loader, repeat):\n",
    "    ELBO_fun = pydpf.ElBO_Loss()\n",
    "    if experiment == 'Kernel':\n",
    "        opt = torch.optim.SGD([{'params': [dpf.SSM.proposal_model.x_weight], 'lr' : 1.}, {'params': [dpf.SSM.proposal_model.y_weight, proposal_model.dist.cholesky_covariance], 'lr' : 1.}, { 'params': dpf.resampler.parameters(), 'lr': 0.01}], lr=.5, momentum=0.9, nesterov=True)\n",
    "    else:\n",
    "        opt = torch.optim.SGD([{'params': [dpf.SSM.proposal_model.x_weight], 'lr' : 1.}, {'params': [dpf.SSM.proposal_model.y_weight, proposal_model.dist.cholesky_covariance], 'lr' : 5.}], lr=.5, momentum=0.9, nesterov=True)\n",
    "    opt_scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.99)\n",
    "    best_validation_loss = torch.inf\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        dpf.train()\n",
    "        total_size = 0\n",
    "        train_loss = []\n",
    "        for state, observation in train_loader:\n",
    "            dpf.update()\n",
    "            opt.zero_grad()\n",
    "            ELBO = dpf(100, 100, ELBO_fun, observation=observation)\n",
    "            loss = torch.mean(ELBO)\n",
    "            loss.backward()\n",
    "            if experiment == 'Kernel':\n",
    "                torch.nn.utils.clip_grad_norm_(dpf.resampler.parameters(), 1., norm_type='inf', error_if_nonfinite=True)\n",
    "            train_loss.append(loss.item()*state.size(1))\n",
    "            opt.step()\n",
    "            total_size += state.size(1)\n",
    "            opt_scheduler.step()\n",
    "        train_loss = np.sum(np.array(train_loss)) / total_size\n",
    "        \n",
    "        dpf.eval()\n",
    "        dpf.update()\n",
    "        total_size = 0\n",
    "        validation_loss = []\n",
    "        with torch.inference_mode():\n",
    "            for state, observation in train_loader:\n",
    "                ELBO = dpf(100, 100, ELBO_fun, observation=observation)\n",
    "                loss = torch.mean(ELBO)\n",
    "                validation_loss.append(loss.item()*state.size(1))\n",
    "                total_size += state.size(1)\n",
    "            validation_loss = np.sum(np.array(validation_loss)) / total_size\n",
    "    \n",
    "        if validation_loss < best_validation_loss:\n",
    "            best_validation_loss = validation_loss\n",
    "            best_dict = deepcopy(dpf.state_dict())\n",
    "        dpf.load_state_dict(best_dict)"
   ],
   "id": "9f53e4574481d6f",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:51:14.133159Z",
     "start_time": "2025-06-05T12:51:14.128354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fractional_diff_exp(a, b):\n",
    "    frac = b-a\n",
    "    return torch.abs(1 - torch.exp(frac))\n",
    "\n",
    "def test_dpf(dpf, test_loader, KalmanFilter):\n",
    "    aggregation_fun = {'ELBO': pydpf.ElBO_Loss(), 'Filtering Mean': pydpf.FilteringMean(), 'Likelihood_factors': pydpf.LogLikelihoodFactors()}\n",
    "    test_ELBO = []\n",
    "    epsilon_x = []\n",
    "    epsilon_l = []\n",
    "    dpf.update()\n",
    "    total_size = 0\n",
    "    for n, p in dpf.named_parameters():\n",
    "        print(n)\n",
    "        if p.dim() == 2:\n",
    "            print(torch.diag(p))\n",
    "        else:\n",
    "            print(p)\n",
    "    with torch.inference_mode():\n",
    "        for state, observation in test_loader:\n",
    "            outputs = dpf(n_particles = 100, time_extent=1000, aggregation_function=aggregation_fun, observation=observation)\n",
    "            test_ELBO.append(outputs['ELBO'].sum().item() * state.size(1))\n",
    "            kalman_state, kalman_cov, kalman_likelihood = KalmanFilter(observation=observation, time_extent=1000)\n",
    "            epsilon_x.append(torch.sum((outputs['Filtering Mean'] - kalman_state)**2, dim=-1).mean().item() * state.size(1))\n",
    "            log_abs_likelihood_error = fractional_diff_exp(kalman_likelihood, outputs['Likelihood_factors'].squeeze()).mean()\n",
    "            epsilon_l.append(log_abs_likelihood_error.item() * state.size(1))\n",
    "            total_size += state.size(1)\n",
    "    return -sum(test_ELBO)/total_size, sum(epsilon_x)/total_size, sum(epsilon_l)/total_size\n",
    "    "
   ],
   "id": "5aa3ab10abfbbe6f",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:51:14.161395Z",
     "start_time": "2025-06-05T12:51:14.157348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def max_wass_dist(x_weight, y_weight, prop_cov):\n",
    "    optimal_x_weight = torch.ones(dx, device=device)\n",
    "    optimal_x_weight[:dy] = .5\n",
    "    optimal_cov = torch.ones(dx, device=device)\n",
    "    for i in range(dy):\n",
    "        optimal_cov[i] = .5\n",
    "    a = x_weight - optimal_x_weight\n",
    "    b = y_weight - .5\n",
    "    if torch.all(a == 0):\n",
    "        mean_div = torch.zeros(dy, device=device)\n",
    "    else:\n",
    "        mean_div = a**2/torch.sum(a**2)\n",
    "    if torch.all(b == 0):\n",
    "        y_mean_div_contr = 0\n",
    "    else:\n",
    "        y_mean_div_contr = b**2/torch.sum(b**2)\n",
    "    mean_div[:dy] += y_mean_div_contr\n",
    "    mean_div = torch.sum(mean_div**2)\n",
    "    cov_div = torch.sum((optimal_cov + prop_cov - 2*torch.sqrt(optimal_cov*prop_cov)))\n",
    "    return mean_div + cov_div\n",
    "    "
   ],
   "id": "a14d1c71210a3be3",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:51:14.187349Z",
     "start_time": "2025-06-05T12:51:14.183830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chain(*its):\n",
    "    it_list = []\n",
    "    for it in its:\n",
    "        it_list += list(it)\n",
    "    return it_list\n",
    "        \n",
    "def rotate_range(c_repeat, rel_start, rel_end, repeats, total_elements):\n",
    "    range_rotation_amount = (total_elements // repeats)*c_repeat\n",
    "    start = (rel_start + range_rotation_amount) % total_elements\n",
    "    end = (rel_end + range_rotation_amount) % total_elements\n",
    "    if end == 0:\n",
    "        return range(start, total_elements)\n",
    "    if start > end:\n",
    "        return chain(range(start, total_elements), range(0, end))\n",
    "    return range(start, end)\n",
    "    "
   ],
   "id": "f65eb42d05b7c77a",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:56:12.934621Z",
     "start_time": "2025-06-05T12:51:14.215927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = pydpf.StateSpaceDataset(data_path=data_path, \n",
    "                        series_id_column='series_id', \n",
    "                        state_prefix='state', \n",
    "                        observation_prefix='observation', \n",
    "                        device=device)\n",
    "if dy > dx:\n",
    "    raise ValueError('The dimension of the observations cannot be more than the dimension of the states.')\n",
    "\n",
    "for experiment in experiment_list:\n",
    "    mean_wass_dist = torch.tensor(0., device=device)\n",
    "    mean_epsilon_l = 0\n",
    "    mean_epsilon_x = 0\n",
    "    mean_ELBO = 0\n",
    "    for repeat in range(n_repeats):\n",
    "        cpu_gen = torch.Generator().manual_seed(10*repeat)\n",
    "        cuda_gen = torch.Generator(device=device).manual_seed(10*repeat)\n",
    "        train_set = torch.utils.data.Subset(dataset, rotate_range(repeat, 0, 1000, n_repeats, 2000))\n",
    "        validation_set = torch.utils.data.Subset(dataset, rotate_range(repeat, 1000, 1500, n_repeats, 2000))\n",
    "        test_set = torch.utils.data.Subset(dataset, rotate_range(repeat, 1500, 2000, n_repeats, 2000))\n",
    "        prior_model, dynamic_model , observation_model, proposal_model = make_model_componets(dx, dy, cuda_gen, experiment == 'Optimal')\n",
    "        if experiment == 'Bootstrap':\n",
    "            SSM = pydpf.FilteringModel(prior_model=prior_model, dynamic_model=dynamic_model, observation_model=observation_model)\n",
    "            dpf = get_DPF('DPF', SSM, dx)\n",
    "            if repeat == 0:\n",
    "                mean_wass_dist = max_wass_dist(torch.ones(dx, device=device), torch.zeros(dy, device=device), torch.ones(dx, device=device)) * n_repeats\n",
    "        elif experiment == 'Optimal':\n",
    "            SSM = pydpf.FilteringModel(prior_model=prior_model, dynamic_model=dynamic_model, observation_model=observation_model, proposal_model=proposal_model)\n",
    "            dpf = get_DPF('DPF', SSM, dx)\n",
    "        else:\n",
    "            trained_model = pydpf.FilteringModel(prior_model=prior_model, dynamic_model=dynamic_model, observation_model=observation_model, proposal_model=proposal_model)\n",
    "            dpf = get_DPF(experiment, trained_model, dx)\n",
    "            train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, generator=cpu_gen, collate_fn=dataset.collate)\n",
    "            validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=32, shuffle=False, generator=cpu_gen, collate_fn=dataset.collate)\n",
    "            training_loop(dpf, 5, train_loader, validation_loader, repeat)\n",
    "            cholesky_prop_cov = torch.diag(proposal_model.dist.cholesky_covariance)\n",
    "            prop_cov = cholesky_prop_cov**2\n",
    "            mean_wass_dist += max_wass_dist(proposal_model.x_weight, proposal_model.y_weight, prop_cov)\n",
    "            \n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(validation_set, batch_size=32, shuffle=False, generator=cpu_gen, collate_fn=dataset.collate)\n",
    "        kalman_filter = pydpf.KalmanFilter(prior_model=prior_model, dynamic_model=dynamic_model, observation_model=observation_model)\n",
    "        ELBO, e_x, e_l = test_dpf(dpf, test_loader, kalman_filter)\n",
    "        mean_ELBO += ELBO\n",
    "        mean_epsilon_l += e_l\n",
    "        mean_epsilon_x += e_x\n",
    "    mean_wass_dist = sqrt(mean_wass_dist.item() / n_repeats)\n",
    "    mean_ELBO = mean_ELBO / n_repeats\n",
    "    mean_epsilon_x = mean_epsilon_x / n_repeats\n",
    "    mean_epsilon_l = mean_epsilon_l / n_repeats\n",
    "    results_df = pd.read_csv(result_path, index_col=0)\n",
    "    row = np.array([mean_epsilon_x, mean_epsilon_l, mean_wass_dist, mean_ELBO])\n",
    "    results_df.loc[experiment] = row\n",
    "    results_df.to_csv(result_path)\n",
    "    print(results_df)"
   ],
   "id": "e147552246f81716",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [04:57<07:25, 148.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[50], line 34\u001B[0m\n\u001B[0;32m     32\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(train_set, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, generator\u001B[38;5;241m=\u001B[39mcpu_gen, collate_fn\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mcollate)\n\u001B[0;32m     33\u001B[0m validation_loader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(validation_set, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, generator\u001B[38;5;241m=\u001B[39mcpu_gen, collate_fn\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mcollate)\n\u001B[1;32m---> 34\u001B[0m training_loop(dpf, \u001B[38;5;241m5\u001B[39m, train_loader, validation_loader, repeat)\n\u001B[0;32m     35\u001B[0m cholesky_prop_cov \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdiag(proposal_model\u001B[38;5;241m.\u001B[39mdist\u001B[38;5;241m.\u001B[39mcholesky_covariance)\n\u001B[0;32m     36\u001B[0m prop_cov \u001B[38;5;241m=\u001B[39m cholesky_prop_cov\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m\n",
      "Cell \u001B[1;32mIn[46], line 16\u001B[0m, in \u001B[0;36mtraining_loop\u001B[1;34m(dpf, epochs, train_loader, validation_loader, repeat)\u001B[0m\n\u001B[0;32m     14\u001B[0m dpf\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[0;32m     15\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 16\u001B[0m ELBO \u001B[38;5;241m=\u001B[39m dpf(\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m100\u001B[39m, ELBO_fun, observation\u001B[38;5;241m=\u001B[39mobservation)\n\u001B[0;32m     17\u001B[0m loss \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(ELBO)\n\u001B[0;32m     18\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\dpf-baselining\\pydpf\\filtering.py:157\u001B[0m, in \u001B[0;36mSIS.forward\u001B[1;34m(self, n_particles, time_extent, aggregation_function, observation, gradient_regulariser, ground_truth, control, time, series_metadata)\u001B[0m\n\u001B[0;32m    155\u001B[0m prev_state \u001B[38;5;241m=\u001B[39m state\n\u001B[0;32m    156\u001B[0m prev_weight \u001B[38;5;241m=\u001B[39m weight\n\u001B[1;32m--> 157\u001B[0m state, weight, likelihood \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproposal(prev_state \u001B[38;5;241m=\u001B[39m prev_state, prev_weight \u001B[38;5;241m=\u001B[39m prev_weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtime_data)\n\u001B[0;32m    158\u001B[0m likelihood \u001B[38;5;241m=\u001B[39m likelihood \u001B[38;5;241m-\u001B[39m log_N\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m gradient_regulariser \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\dpf-baselining\\pydpf\\filtering.py:295\u001B[0m, in \u001B[0;36mParticleFilter._register_functions.<locals>.pf_sampler\u001B[1;34m(prev_state, prev_weight, **data)\u001B[0m\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpf_sampler\u001B[39m(prev_state, prev_weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata):\n\u001B[1;32m--> 295\u001B[0m     resampled_x, resampled_w \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresampler(prev_state, prev_weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n\u001B[0;32m    296\u001B[0m     state, weight \u001B[38;5;241m=\u001B[39m prop(prev_state\u001B[38;5;241m=\u001B[39mresampled_x, prev_weight\u001B[38;5;241m=\u001B[39mresampled_w, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n\u001B[0;32m    297\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\dpf-baselining\\pydpf\\resampling.py:311\u001B[0m, in \u001B[0;36mOptimalTransportResampler.forward\u001B[1;34m(self, state, weight, **data)\u001B[0m\n\u001B[0;32m    309\u001B[0m N \u001B[38;5;241m=\u001B[39m state\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    310\u001B[0m log_b, cost, extent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_sinkhorn_inputs_OT(N, weight, state)\n\u001B[1;32m--> 311\u001B[0m f, g, epsilon_used \u001B[38;5;241m=\u001B[39m optimal_transport\u001B[38;5;241m.\u001B[39msinkhorn_loop(weight, log_b, cost, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregularisation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_update_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_iterations, extent\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecay_rate)\n\u001B[0;32m    312\u001B[0m transport \u001B[38;5;241m=\u001B[39m optimal_transport\u001B[38;5;241m.\u001B[39mget_transport_from_potentials(weight, log_b, cost, f, g, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregularisation)\n\u001B[0;32m    313\u001B[0m transport \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_wrapper\u001B[38;5;241m.\u001B[39mapply(transport)\n",
      "File \u001B[1;32m~\\PycharmProjects\\dpf-baselining\\pydpf\\optimal_transport.py:150\u001B[0m, in \u001B[0;36msinkhorn_loop\u001B[1;34m(log_a, log_b, cost, epsilon, threshold, max_iter, diam, rate)\u001B[0m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;66;03m#Point convergence, the gradient due to the last step can be substituted for the gradient of the whole loop.\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 150\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m stop_criterion(i, continue_criterion):\n\u001B[0;32m    151\u001B[0m         f_u \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mwhere(continue_criterion, (f_i \u001B[38;5;241m+\u001B[39m opt_potential(log_b, g_i, cost, epsilon_now)) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m, f_i)\n\u001B[0;32m    152\u001B[0m         g_u \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mwhere(continue_criterion, (g_i \u001B[38;5;241m+\u001B[39m opt_potential(log_a, f_i, cost_T, epsilon_now)) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m, g_i)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
