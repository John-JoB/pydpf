{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Filtering a fully specified model",
   "id": "5ddfa83c608d71e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Before running this notebook: ensure that the steps outlined in sv_setup_instructions.txt are complete",
   "id": "5cb2733037b0e4d1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pydpf\n",
    "import numpy as np\n",
    "import torch\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from sv_model import make_SSM\n",
    "import pandas as pd\n",
    "from time import time"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Settings",
   "id": "b5856954ed3d7ddf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "experiments =  ['DPF', 'Soft', 'Stop-Gradient', 'Marginal Stop-Gradient', 'Optimal Transport', 'Kernel']\n",
    "alpha = 0.91\n",
    "beta = 0.5\n",
    "sigma = 1.\n",
    "batch_size = 128\n",
    "data_path = pathlib.Path('.').parent.absolute().joinpath(f'data/alpha={alpha}-beta={beta}-sigma={sigma}.csv')\n",
    "result_path = pathlib.Path('.').parent.absolute().joinpath('results/fully_specified_results.csv')\n"
   ],
   "id": "85384407961b67a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_DPF(DPF_type):\n",
    "    if DPF_type == 'DPF':\n",
    "        return pydpf.DPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Soft':\n",
    "        return pydpf.SoftDPF(SSM=SSM, resampling_generator=experiment_cuda_rng, softness=0.7)\n",
    "    if DPF_type == 'Stop-Gradient':\n",
    "        return pydpf.StopGradientDPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Marginal Stop-Gradient':\n",
    "        return pydpf.MarginalStopGradientDPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Optimal Transport':\n",
    "        return pydpf.OptimalTransportDPF(SSM=SSM, regularisation=0.5, transport_gradient_clip=1.)\n",
    "    if DPF_type == 'Kernel':\n",
    "        kernel = pydpf.KernelMixture(pydpf.MultivariateGaussian(torch.zeros(1, device=device),torch.eye(1, device=device)*0.1, generator=experiment_cuda_rng), generator=experiment_cuda_rng)\n",
    "        return pydpf.KernelDPF(SSM=SSM, kernel=kernel)\n",
    "    raise ValueError('DPF_type should be one of the allowed options')"
   ],
   "id": "8f31123ac7b5a03f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fractional_diff_exp(a, b):\n",
    "    frac = b-a\n",
    "    return torch.abs(1 - torch.exp(frac))"
   ],
   "id": "96fceda67ee4bb26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "alpha_t = torch.tensor([[alpha]], device=device)\n",
    "beta_t =torch.tensor([beta], device=device)\n",
    "sigma_t = torch.tensor([[sigma]], device=device)\n",
    "dataset = pydpf.StateSpaceDataset(data_path=data_path, series_id_column='series_id', state_prefix='state', observation_prefix='observation', device=device)\n"
   ],
   "id": "771d91d2d606cf00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for experiment in experiments:\n",
    "    print(f\"Testing {experiment}\")\n",
    "    experiment_cuda_rng = torch.Generator(device=device).manual_seed(0)\n",
    "    experiment_cpu_rng = torch.Generator().manual_seed(0)\n",
    "    size = 0\n",
    "    pf_time = []\n",
    "    MSE = []\n",
    "    likelihood_error = []\n",
    "    SSM = make_SSM(sigma_t, alpha_t, beta_t, device, generator=experiment_cuda_rng)\n",
    "    dpf = get_DPF(experiment)\n",
    "    pf = pydpf.DPF(SSM=SSM, resampling_generator=experiment_cuda_rng, multinomial=True)\n",
    "    aggregation_function = {'Likelihood': pydpf.LogLikelihoodFactors(), 'Filtering mean': pydpf.FilteringMean()}\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, generator=experiment_cpu_rng, collate_fn=dataset.collate)\n",
    "    for state, observation in tqdm(data_loader):\n",
    "        with torch.inference_mode():\n",
    "            size += state.size(1)\n",
    "            true_outputs = pf(observation=observation, n_particles=10000, aggregation_function=aggregation_function, time_extent=1000)\n",
    "            torch.cuda.synchronize()\n",
    "            s_time = time()\n",
    "            outputs = dpf(observation=observation, n_particles=100, aggregation_function=aggregation_function, time_extent=1000)\n",
    "            torch.cuda.synchronize()\n",
    "            pf_time.append((time() - s_time))\n",
    "            MSE.append(torch.sum((true_outputs['Filtering mean'] - outputs['Filtering mean'])**2, dim=-1).mean().item()*state.size(1))\n",
    "            likelihood_error.append(fractional_diff_exp(true_outputs['Likelihood'], outputs['Likelihood']).mean().item()*state.size(1))\n",
    "\n",
    "    \n",
    "    results = pd.read_csv(result_path, index_col=0)\n",
    "    row = np.array([sum(MSE) / size, sum(likelihood_error) / size, sum(pf_time[1:-1]) / (len(data_loader) - 2)])\n",
    "    results.loc[experiment] = row\n",
    "    print(results)\n",
    "    results.to_csv(result_path)"
   ],
   "id": "4e6528761e15acea",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
