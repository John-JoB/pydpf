{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-13T14:08:03.238103Z",
     "start_time": "2025-06-13T14:08:03.234512Z"
    }
   },
   "source": [
    "import pydpf\n",
    "import numpy as np\n",
    "import torch\n",
    "import pathlib\n",
    "import model\n",
    "from tqdm import tqdm\n",
    "from model import make_SSM\n",
    "import pandas as pd\n",
    "from time import time"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:08:03.246071Z",
     "start_time": "2025-06-13T14:08:03.238103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "experiment_cuda_rng = torch.Generator(device=device).manual_seed(0)\n",
    "experiment_cpu_rng = torch.Generator().manual_seed(0)\n",
    "DPF_type = 'Kernel'\n",
    "data_path = pathlib.Path('.').parent.absolute().joinpath('data.csv')\n"
   ],
   "id": "85384407961b67a5",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:08:03.543294Z",
     "start_time": "2025-06-13T14:08:03.539529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_DPF(SSM):\n",
    "    if DPF_type == 'DPF':\n",
    "        return pydpf.DPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Soft':\n",
    "        return pydpf.SoftDPF(SSM=SSM, resampling_generator=experiment_cuda_rng, softness=0.5)\n",
    "    if DPF_type == 'Stop-Gradient':\n",
    "        return pydpf.StopGradientDPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Marginal Stop-Gradient':\n",
    "        return pydpf.MarginalStopGradientDPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Optimal Transport':\n",
    "        return pydpf.OptimalTransportDPF(SSM=SSM, regularisation=0.5, transport_gradient_clip=1.)\n",
    "    if DPF_type == 'Kernel':\n",
    "        kernel = pydpf.KernelMixture(pydpf.MultivariateGaussian(torch.zeros(1, device=device),torch.eye(1, device=device)*0.1, generator=experiment_cuda_rng), generator=experiment_cuda_rng)\n",
    "        return pydpf.KernelDPF(SSM=SSM, kernel=kernel)\n",
    "    raise ValueError('DPF_type should be one of the allowed options')"
   ],
   "id": "8f31123ac7b5a03f",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:08:03.548434Z",
     "start_time": "2025-06-13T14:08:03.544301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fractional_diff_exp(a, b):\n",
    "    frac = b-a\n",
    "    return torch.abs(1 - torch.exp(frac))"
   ],
   "id": "96fceda67ee4bb26",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:08:03.701711Z",
     "start_time": "2025-06-13T14:08:03.689106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_gen_generator = torch.Generator(device=device).manual_seed(0)\n",
    "alpha = torch.tensor([[0.91]], device=device)\n",
    "beta =torch.tensor([0.5], device=device)\n",
    "sigma = torch.tensor([[1.]], device=device)\n",
    "SSM = make_SSM(sigma, alpha, beta, device, generator=data_gen_generator)\n",
    "#pydpf.simulate_and_save(data_path, SSM=SSM, time_extent=1000, n_trajectories=500, batch_size=100, device=device)"
   ],
   "id": "771d91d2d606cf00",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:08:04.047332Z",
     "start_time": "2025-06-13T14:08:03.928635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = pydpf.StateSpaceDataset(data_path=data_path, series_id_column='series_id', state_prefix='state', observation_prefix='observation', device=device)\n",
    "dpf = get_DPF(SSM)\n",
    "pf = pydpf.DPF(SSM=SSM, resampling_generator=experiment_cuda_rng, multinomial=True)\n",
    "aggregation_function = {'Likelihood': pydpf.LogLikelihoodFactors(), 'Filtering mean': pydpf.FilteringMean()}\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=30, shuffle=False, generator=experiment_cpu_rng, collate_fn=dataset.collate)"
   ],
   "id": "d51ae5aae0eabc75",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:08:29.915379Z",
     "start_time": "2025-06-13T14:08:04.231863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "size = 0\n",
    "pf_time = []\n",
    "MSE = []\n",
    "likelihood_error = []\n",
    "\n",
    "for state, observation in tqdm(data_loader):\n",
    "    with torch.inference_mode():\n",
    "        size += state.size(1)\n",
    "        true_outputs = pf(observation=observation, n_particles=10000, aggregation_function=aggregation_function, time_extent=1000)\n",
    "        s_time = time()\n",
    "        outputs = dpf(observation=observation, n_particles=100, aggregation_function=aggregation_function, time_extent=1000)\n",
    "        pf_time.append((time() - s_time))\n",
    "        MSE.append(torch.sum((true_outputs['Filtering mean'] - outputs['Filtering mean'])**2, dim=-1).mean().item()*state.size(1))\n",
    "        likelihood_error.append(fractional_diff_exp(true_outputs['Likelihood'], outputs['Likelihood']).mean().item()*state.size(1))"
   ],
   "id": "4e6528761e15acea",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:25<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:08:29.942449Z",
     "start_time": "2025-06-13T14:08:29.936463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_path = pathlib.Path('.').parent.absolute().joinpath('fully_specified_results.csv')\n",
    "results = pd.read_csv(result_path, index_col=0)\n",
    "row = np.array([sum(MSE)/size, sum(likelihood_error)/size, sum(pf_time[1:-1])/(len(data_loader)-2)])\n",
    "results.loc[DPF_type] = row\n",
    "print(results)\n",
    "results.to_csv(result_path)"
   ],
   "id": "6a5f290ea3cde933",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             e_x       e_l       time\n",
      "method                                               \n",
      "DPF                     0.026536  0.063251   0.712928\n",
      "Soft                    0.028045  0.068421   0.861655\n",
      "Stop-Gradient           0.026536  0.063251   0.735490\n",
      "Marginal Stop-Gradient  0.026536  0.063251   0.739505\n",
      "Optimal Transport       0.048391  0.078096  54.498954\n",
      "Kernel                  0.032957  0.072445   0.781434\n"
     ]
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
