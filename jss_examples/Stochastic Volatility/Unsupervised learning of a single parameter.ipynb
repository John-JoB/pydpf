{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-13T14:18:48.528838Z",
     "start_time": "2025-06-13T14:18:44.374672Z"
    }
   },
   "source": [
    "import pydpf\n",
    "import numpy as np\n",
    "import torch\n",
    "import pathlib\n",
    "import model\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from training_loop import train\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:18:48.572413Z",
     "start_time": "2025-06-13T14:18:48.528838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DPF_type = 'Optimal Transport'\n",
    "n_repeats = 10\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "4ccc64ac86d7b6ed",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:18:48.810017Z",
     "start_time": "2025-06-13T14:18:48.804668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_DPF(SSM):\n",
    "    if DPF_type == 'DPF':\n",
    "        return pydpf.DPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Soft':\n",
    "        return pydpf.SoftDPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Stop-Gradient':\n",
    "        return pydpf.StopGradientDPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Marginal Stop-Gradient':\n",
    "        return pydpf.MarginalStopGradientDPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Optimal Transport':\n",
    "        return pydpf.OptimalTransportDPF(SSM=SSM, regularisation=0.5, transport_gradient_clip=1.)\n",
    "    if DPF_type == 'Kernel':\n",
    "        kernel = pydpf.KernelMixture(pydpf.MultivariateGaussian(torch.zeros(1, device=device),torch.nn.Parameter(torch.eye(1, device=device)*0.1), generator=experiment_cuda_rng), generator=experiment_cuda_rng)\n",
    "        return pydpf.KernelDPF(SSM=SSM, kernel=kernel)\n",
    "    raise ValueError('DPF_type should be one of the allowed options')"
   ],
   "id": "9cf2a81ff69115d0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:19:09.625319Z",
     "start_time": "2025-06-13T14:18:48.818722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "experiment_cuda_rng = torch.Generator(device).manual_seed(0)\n",
    "generation_rng = torch.Generator(device).manual_seed(0)\n",
    "aggregation_function_dict = {'ELBO': pydpf.LogLikelihoodFactors()}\n",
    "test_dataset = pydpf.StateSpaceDataset(data_path=pathlib.Path('.').parent.absolute().joinpath('test_trajectory.csv'), state_prefix='state', device='cuda')\n",
    "Gradients = []\n",
    "size = 0\n",
    "alpha_p = torch.nn.Parameter(torch.tensor([[0.93]], dtype = torch.float32, device=device))\n",
    "SSM = model.make_SSM(torch.tensor([[1.]], device=device), alpha_p, torch.tensor([0.5], device=device), device)\n",
    "DPF = get_DPF(SSM)\n",
    "forward_time = []\n",
    "backward_time = []\n",
    "state = test_dataset.state[:,0:1].expand((101, 100, 1)).contiguous()\n",
    "observation = test_dataset.observation[:,0:1].expand((101, 100, 1)).contiguous()\n",
    "for i in tqdm(range(20)):\n",
    "    DPF.update()\n",
    "    size += state.size(1)\n",
    "    start = time()\n",
    "    outputs = DPF(observation=observation, n_particles=100, ground_truth=state, aggregation_function=aggregation_function_dict, time_extent=100)\n",
    "    ls = torch.mean(outputs['ELBO'], dim=0)\n",
    "    loss = ls.mean()\n",
    "    forward_time.append((time() - start))\n",
    "    start = time()\n",
    "    loss.backward(retain_graph=True)\n",
    "    backward_time.append((time() - start))\n",
    "    alpha_p.grad = None\n",
    "    for i in range(len(ls)):\n",
    "        ls[i].backward(retain_graph=True)\n",
    "        Gradients.append(alpha_p.grad.item())\n",
    "        alpha_p.grad = None\n",
    "    loss.backward()"
   ],
   "id": "aa57f4668382c639",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 1/20 [00:20<06:24, 20.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 27\u001B[0m\n\u001B[0;32m     25\u001B[0m alpha_p\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(ls)):\n\u001B[1;32m---> 27\u001B[0m     ls[i]\u001B[38;5;241m.\u001B[39mbackward(retain_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     28\u001B[0m     Gradients\u001B[38;5;241m.\u001B[39mappend(alpha_p\u001B[38;5;241m.\u001B[39mgrad\u001B[38;5;241m.\u001B[39mitem())\n\u001B[0;32m     29\u001B[0m     alpha_p\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    580\u001B[0m     )\n\u001B[1;32m--> 581\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[0;32m    582\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[0;32m    583\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m _engine_run_backward(\n\u001B[0;32m    348\u001B[0m     tensors,\n\u001B[0;32m    349\u001B[0m     grad_tensors_,\n\u001B[0;32m    350\u001B[0m     retain_graph,\n\u001B[0;32m    351\u001B[0m     create_graph,\n\u001B[0;32m    352\u001B[0m     inputs,\n\u001B[0;32m    353\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    354\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    355\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    827\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:19:09.716063500Z",
     "start_time": "2025-06-13T13:36:34.997466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alphas = np.empty(n_repeats)\n",
    "data_path = pathlib.Path('.').parent.absolute().joinpath('data.csv')\n",
    "for n in range(n_repeats):\n",
    "    experiment_cuda_rng = torch.Generator(device).manual_seed(n*10)\n",
    "    experiment_cpu_rng = torch.Generator().manual_seed(n*10)\n",
    "    generation_rng = torch.Generator(device).manual_seed(n*10)\n",
    "    true_SSM = model.make_SSM(torch.tensor([[1.]], device=device), torch.tensor([[0.91]], device=device), torch.tensor([0.5], device=device), device, generation_rng)\n",
    "    pydpf.simulate_and_save(data_path, SSM=true_SSM, time_extent=1000, n_trajectories=500, batch_size=100, device=device, bypass_ask=True)\n",
    "    alpha = torch.nn.Parameter(torch.rand((1,1), device=device, generator=experiment_cuda_rng), requires_grad=True)\n",
    "    SSM = model.make_SSM(torch.tensor([[1.]], device=device), alpha, torch.tensor([0.5], device=device), device, generation_rng)\n",
    "    dpf = get_DPF(SSM)\n",
    "    if DPF_type == 'Kernel':\n",
    "        opt = torch.optim.SGD([{'params':[alpha], 'lr':0.05}, {'params':dpf.resampler.mixture.parameters(), 'lr':0.01}])\n",
    "    else:\n",
    "        opt = torch.optim.SGD([{'params':[alpha], 'lr':0.05}])\n",
    "    opt_schedule = torch.optim.lr_scheduler.ExponentialLR(opt, 0.95)\n",
    "    dataset = pydpf.StateSpaceDataset(data_path, state_prefix='state', device=device)\n",
    "    _, ELBO = train(dpf, opt, dataset, 10, (100, 100, 100), (30, 100, 100), (0.5, 0.25, 0.25), 1., experiment_cpu_rng, target='ELBO', time_extent=100, lr_scheduler=opt_schedule)\n",
    "    print(alpha)\n",
    "    alphas[n] = alpha\n"
   ],
   "id": "f770de140baeca54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done                  \n",
      "\n",
      "epoch 1/10, train loss: 1.3528409481048584, validation MSE: 2.424424648284912, validation ELBO: -130.94684143066405\n",
      "epoch 2/10, train loss: 1.2742947626113892, validation MSE: 2.8925307750701905, validation ELBO: -145.71783752441405\n",
      "epoch 3/10, train loss: 1.2814369821548461, validation MSE: 2.5621196746826174, validation ELBO: -134.63070220947264\n",
      "epoch 4/10, train loss: 1.1772432327270508, validation MSE: 1.763780689239502, validation ELBO: -115.36298828125\n",
      "epoch 5/10, train loss: 1.1188967895507813, validation MSE: 1.9161650657653808, validation ELBO: -117.99909210205078\n",
      "epoch 6/10, train loss: 1.164355399608612, validation MSE: 2.470067548751831, validation ELBO: -132.15218505859374\n",
      "epoch 7/10, train loss: 1.274304714202881, validation MSE: 2.5998330116271973, validation ELBO: -136.25420837402345\n",
      "epoch 8/10, train loss: 1.247541527748108, validation MSE: 2.5000436782836912, validation ELBO: -133.1541534423828\n",
      "epoch 9/10, train loss: 1.272823281288147, validation MSE: 2.4667576789855956, validation ELBO: -132.02997131347655\n",
      "epoch 10/10, train loss: 1.2110919332504273, validation MSE: 2.0252748012542723, validation ELBO: -120.69220275878907\n",
      "\n",
      "test MSE: 1.8806833505630494, test ELBO: -125.26387023925781\n",
      "Parameter containing:\n",
      "tensor([[0.7174]], device='cuda:0', requires_grad=True)\n",
      "Done                  \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 18\u001B[0m\n\u001B[0;32m     16\u001B[0m opt_schedule \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mExponentialLR(opt, \u001B[38;5;241m0.95\u001B[39m)\n\u001B[0;32m     17\u001B[0m dataset \u001B[38;5;241m=\u001B[39m pydpf\u001B[38;5;241m.\u001B[39mStateSpaceDataset(data_path, state_prefix\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstate\u001B[39m\u001B[38;5;124m'\u001B[39m, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m---> 18\u001B[0m _, ELBO \u001B[38;5;241m=\u001B[39m train(dpf, opt, dataset, \u001B[38;5;241m10\u001B[39m, (\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m100\u001B[39m), (\u001B[38;5;241m30\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m100\u001B[39m), (\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.25\u001B[39m, \u001B[38;5;241m0.25\u001B[39m), \u001B[38;5;241m1.\u001B[39m, experiment_cpu_rng, target\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mELBO\u001B[39m\u001B[38;5;124m'\u001B[39m, time_extent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, lr_scheduler\u001B[38;5;241m=\u001B[39mopt_schedule)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(alpha)\n\u001B[0;32m     20\u001B[0m alphas[n] \u001B[38;5;241m=\u001B[39m alpha\n",
      "File \u001B[1;32m~\\PycharmProjects\\pydpf\\jss_examples\\Stochastic Volatility\\training_loop.py:68\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(dpf, opt, dataset, epochs, n_particles, batch_size, split_size, likelihood_scaling, data_loading_generator, gradient_regulariser, target, time_extent, lr_scheduler, clamp)\u001B[0m\n\u001B[0;32m     66\u001B[0m dpf\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[0;32m     67\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 68\u001B[0m loss \u001B[38;5;241m=\u001B[39m dpf(n_particles[\u001B[38;5;241m0\u001B[39m], time_extent, aggregation_function, observation\u001B[38;5;241m=\u001B[39mobservation, ground_truth\u001B[38;5;241m=\u001B[39mstate, gradient_regulariser \u001B[38;5;241m=\u001B[39m gradient_regulariser)\n\u001B[0;32m     69\u001B[0m loss \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(loss[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mELBO\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m*\u001B[39mlikelihood_scaling \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39mlikelihood_scaling)\u001B[38;5;241m*\u001B[39mtorch\u001B[38;5;241m.\u001B[39mmean(loss[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMSE\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     70\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\pydpf\\pydpf\\filtering.py:170\u001B[0m, in \u001B[0;36mSIS.forward\u001B[1;34m(self, n_particles, time_extent, aggregation_function, observation, gradient_regulariser, ground_truth, control, time, series_metadata)\u001B[0m\n\u001B[0;32m    168\u001B[0m state, weight, likelihood \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproposal(prev_state \u001B[38;5;241m=\u001B[39m prev_state, prev_weight \u001B[38;5;241m=\u001B[39m prev_weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtime_data)\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_dict:\n\u001B[1;32m--> 170\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m name, function \u001B[38;5;129;01min\u001B[39;00m aggregation_function\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    171\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m gt_exists:\n\u001B[0;32m    172\u001B[0m             output[name][t] \u001B[38;5;241m=\u001B[39m function(state\u001B[38;5;241m=\u001B[39mstate, weight\u001B[38;5;241m=\u001B[39mweight, likelihood\u001B[38;5;241m=\u001B[39mlikelihood, ground_truth\u001B[38;5;241m=\u001B[39mground_truth[t], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtime_data)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:19:09.726620500Z",
     "start_time": "2025-06-13T13:14:22.723304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_path = pathlib.Path('.').parent.absolute().joinpath('single_parameter_results.csv')\n",
    "results = pd.read_csv(result_path, index_col=0)\n",
    "row = np.array([sum(forward_time[1:-1])/(len(forward_time)-2), sum(backward_time[1:-1])/(len(backward_time)-2), np.sqrt(np.var(Gradients)), np.mean(np.abs(alphas - 0.91))])\n",
    "results.loc[DPF_type] = row\n",
    "print(results)\n",
    "results.to_csv(result_path)"
   ],
   "id": "62b835a506c49f6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Forward Time (s)  Backward Time (s)  \\\n",
      "method                                                        \n",
      "DPF                             0.171809           0.052404   \n",
      "Soft                            0.170429           0.078622   \n",
      "Stop-Gradient                   0.201992           0.078292   \n",
      "Marginal Stop-Gradient          0.130973           0.053427   \n",
      "Optimal Transport               1.089317           0.107106   \n",
      "Kernel                          0.140275           0.078705   \n",
      "\n",
      "                        Gradient standard deviation  alpha error  \n",
      "method                                                            \n",
      "DPF                                        0.034926     0.002912  \n",
      "Soft                                       0.375278     0.006917  \n",
      "Stop-Gradient                              1.145910     0.011383  \n",
      "Marginal Stop-Gradient                     0.477815     0.004123  \n",
      "Optimal Transport                          0.116350     0.025273  \n",
      "Kernel                                     0.343244     0.003794  \n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
